{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f05353-febb-42b8-98db-973d1ad39d66",
   "metadata": {},
   "source": [
    "1. Получение данных о вакансиях с https://api.hh.ru/vacancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdaafe0-0f2d-4d6e-a0b3-0e3bcd5fedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def csv_escape(s):\n",
    "    if isinstance(s, str):\n",
    "        return s.replace('\"', '\"\"')\n",
    "    return str(s) \n",
    "    \n",
    "def get_page(page=0, keywords=['Java', 'TypeScript','JavaScript', 'Python', 'язык C', 'C#', 'C++', 'Go', 'PHP', 'Swift', 'SQL', 'Ruby', 'Kotlin', 'Dart', 'Rust']):\n",
    "    keywords_str = ' OR '.join(keywords)\n",
    "    params = {\n",
    "        'text': keywords_str,\n",
    "        'employment': \"full\",\n",
    "        'only_with_salary' : \"true\",\n",
    "        'area' : 113,\n",
    "        'page': page,\n",
    "        'per_page': 100\n",
    "    }\n",
    "    try:\n",
    "        req = requests.get('https://api.hh.ru/vacancies', params)\n",
    "        req.raise_for_status()  \n",
    "        data = req.content.decode()\n",
    "        req.close()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Ошибка при запросе к API: {e}\")\n",
    "        return None\n",
    "        \n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            items.append((new_key, json.dumps(v))) \n",
    "        elif v is None:\n",
    "            items.append((new_key, ''))\n",
    "        else:\n",
    "            items.append((new_key, csv_escape(v)))\n",
    "    return dict(items)\n",
    "\n",
    "js_objs = []\n",
    "for page in range(0, 20):\n",
    "    page_data = get_page(page)\n",
    "    if page_data:\n",
    "        js_obj = json.loads(page_data)\n",
    "        items = js_obj.get('items', [])\n",
    "        if items: \n",
    "            js_objs.extend(items)\n",
    "            pages = js_obj.get('pages', 0)\n",
    "            if pages <= page +1: \n",
    "                break\n",
    "        else:\n",
    "            print(f\"Вакансий не найдено на странице {page}\")\n",
    "            break \n",
    "    else:\n",
    "        print(f\"Запрос на страницу {page} не удался\")\n",
    "    time.sleep(0.25)\n",
    "\n",
    "print(f\"Найдено вакансий: {len(js_objs)}\")\n",
    "\n",
    "flattened_data = [flatten_dict(vacancy) for vacancy in js_objs]\n",
    "\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "df.to_csv('vacancies.csv', encoding='utf-8', index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "print('Данные сохранены в vacancies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeb2b2f-4871-4796-bb9a-8bd23c50c939",
   "metadata": {},
   "source": [
    "2. Получение данных о репозиториях с https://api.github.com/repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c290bfe-1113-43dc-a4c1-d94c6860c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
    "if not GITHUB_TOKEN:\n",
    "    print(\"Ошибка: Не установлен токен GitHub.\")\n",
    "    exit(1)\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'token {GITHUB_TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "keywords = ['Java', 'TypeScript', 'JavaScript', 'Python', 'C', 'C#', 'C++', 'Go', 'PHP', 'Swift', 'SQL', 'Ruby', 'Kotlin', 'Dart', 'Rust']\n",
    "search_url = 'https://api.github.com/search/repositories'\n",
    "repo_url = \"https://api.github.com/repositories\"  \n",
    "\n",
    "async def fetch_repo_data(session, query, page=1, per_page=100):\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'sort': 'stars',\n",
    "        'per_page': per_page,\n",
    "        'page': page\n",
    "    }\n",
    "    async with session.get(search_url, headers=headers, params=params) as response:\n",
    "        if response.status == 200:\n",
    "            data = await response.json()\n",
    "            return data['items'] if 'items' in data else []\n",
    "        elif response.status == 403:  \n",
    "            print(\"Превышен лимит запросов к GitHub API. Ожидание...\")\n",
    "            await asyncio.sleep(60)  \n",
    "            return await fetch_repo_data(session, query, page, per_page) \n",
    "        else:\n",
    "            print(f\"Ошибка при запросе: {response.status}, {query}\")\n",
    "            return []\n",
    "\n",
    "async def get_languages(session, repo_url):\n",
    "  async with session.get(repo_url + \"/languages\", headers=headers) as response:\n",
    "    if response.status == 200:\n",
    "      return await response.json()\n",
    "    else:\n",
    "      return {}\n",
    "\n",
    "def csv_escape(s):\n",
    "    if isinstance(s, str):\n",
    "        return s.replace('\"', '\"\"')\n",
    "    return str(s)\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            items.append((new_key, json.dumps(v)))\n",
    "        elif v is None:\n",
    "            items.append((new_key, ''))\n",
    "        else:\n",
    "            items.append((new_key, csv_escape(v)))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [fetch_repo_data(session, f'language:{lang}') for lang in keywords]\n",
    "        repo_data = []\n",
    "        for items in await asyncio.gather(*tasks):\n",
    "            repo_data.extend(items)\n",
    "\n",
    "      \n",
    "        for i, repo in enumerate(tqdm(repo_data, desc=\"Обработка репозиториев\")):\n",
    "            languages_data = await get_languages(session, repo['url'])\n",
    "            total_size = sum(languages_data.values())\n",
    "            if total_size > 0:\n",
    "                repo['percentage'] = {lang: round((size / total_size) * 100, 2) for lang, size in languages_data.items()}\n",
    "            else:\n",
    "                repo['percentage'] = {}\n",
    "        return [flatten_dict(repo) for repo in repo_data]\n",
    "\n",
    "try:\n",
    "    repo_data = await main()\n",
    "    df = pd.DataFrame(repo_data)\n",
    "    df.to_csv('github_repos.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "    print('Данные сохранены в github_repos.csv')\n",
    "except Exception as e:\n",
    "    print(f\"Произошла ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2528e011-856e-442b-bd90-1fbec8115013",
   "metadata": {},
   "source": [
    "3. Получение данных о количестве репозиториев с https://api.github.com/search/repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d6870-8c04-490e-a64c-e48962c62fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "keywords = [\n",
    "    'Java', 'TypeScript', 'JavaScript', 'Python', 'C', 'C#', 'C++',\n",
    "    'Go', 'PHP', 'Swift', 'SQL', 'Ruby', 'Kotlin', 'Dart', 'Rust', 'Jupyter Notebook',\n",
    "    'TSQL', 'PLpgSQL', 'PLSQL'\n",
    "]\n",
    "\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
    "headers = {\n",
    "    'Authorization': f'token {GITHUB_TOKEN}',\n",
    "    'Accept': 'application/vnd.github.v3+json'\n",
    "}\n",
    "\n",
    "search_url = 'https://api.github.com/search/repositories'\n",
    "repo_url_base = \"https://api.github.com/repos\"\n",
    "\n",
    "results = []\n",
    "\n",
    "def get_repo_details(repo_url, headers):\n",
    "    try:\n",
    "      response = requests.get(repo_url, headers=headers)\n",
    "      response.raise_for_status()\n",
    "      data = response.json()\n",
    "      return {\n",
    "          'stars': data.get('stargazers_count', 0),\n",
    "          'subscribers': data.get('subscribers_count', 0),\n",
    "          'forks': data.get('forks_count', 0)\n",
    "      }\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "      print(f\"Error fetching repo details: {e}\")\n",
    "      return {}\n",
    "    except Exception as e:\n",
    "      print(f\"Error fetching repo details: {e}\")\n",
    "      return {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for language in keywords:\n",
    "    params = {\n",
    "        'q': f'language:{language}',\n",
    "        'per_page': 10 \n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        total_count = data.get('total_count', 0)\n",
    "        repo_details = []\n",
    "        \n",
    "        if data['items']: \n",
    "            for item in data['items']:\n",
    "              repo_url = f\"{repo_url_base}/{item['owner']['login']}/{item['name']}\"\n",
    "              repo_info = get_repo_details(repo_url, headers)\n",
    "              repo_details.append(repo_info)\n",
    "              time.sleep(random.uniform(0.5,1))\n",
    "        else:\n",
    "          repo_details = []\n",
    "\n",
    "        print(f\"Язык: {language}, Количество репозиториев: {total_count}\")\n",
    "        results.append({\n",
    "            'Language': language,\n",
    "            'RepositoryCount': total_count,\n",
    "            'RepoDetails': repo_details\n",
    "        })\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP ошибка для языка {language}: {http_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Ошибка для языка {language}: {err}\")\n",
    "    \n",
    "\n",
    "\n",
    "import json\n",
    "csv_file = 'language_popularity_details.csv'\n",
    "with open(csv_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Language', 'RepositoryCount', 'RepoDetails']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in results:\n",
    "        row['RepoDetails'] = json.dumps(row['RepoDetails']) #Serialize nested dictionary\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"\\nДанные успешно сохранены в файл {csv_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d0b7d-a092-4e73-a71b-012f83b90d2d",
   "metadata": {},
   "source": [
    "4. Получение данных об обсуждениях на форуме с https://api.stackexchange.com/2.2/search/advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ae796-5510-47e4-b17c-c98b9fa72703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "STACK_EXCHANGE_API_KEY = \"MY_STACK_EXCHAGE_API_KEY\"\n",
    "\n",
    "keywords = ['java', 'typescript', 'javascript', 'python', 'c', 'c#', 'c++', 'go', 'php', 'swift', 'sql', 'ruby', 'kotlin', 'dart', 'rust']\n",
    "site = \"stackoverflow\"\n",
    "\n",
    "def get_posts(page=1, pageSize=100, keyword=None):\n",
    "    if keyword is None:\n",
    "        return [], False\n",
    "\n",
    "    url = f\"https://api.stackexchange.com/2.2/search/advanced?order=desc&sort=activity&site={site}&pagesize={pageSize}&page={page}&tagged={keyword}\"\n",
    "    params = {'key': STACK_EXCHANGE_API_KEY}\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data.get('items', []), data.get('has_more', False)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Ошибка при запросе к API для {keyword}: {e}\")\n",
    "        return [], False\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Ошибка декодирования JSON для {keyword}: {e}. Пропуск страницы.\")\n",
    "        return [], False\n",
    "        \n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            items.append((new_key, json.dumps(v))) \n",
    "        elif v is None:\n",
    "            items.append((new_key, ''))\n",
    "        else:\n",
    "            items.append((new_key, str(v).replace('\"', ''))) \n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "\n",
    "def process_and_save(all_posts):\n",
    "    flattened_data = []\n",
    "    \n",
    "    for post in all_posts:\n",
    "        try:\n",
    "            flattened_data.append(flatten_dict(post))\n",
    "        except (TypeError, KeyError) as e:\n",
    "            print(f\"Ошибка при обработке поста: {e}, пост пропущен.\")\n",
    "\n",
    "    if flattened_data:\n",
    "      df = pd.DataFrame(flattened_data)\n",
    "\n",
    "      try:\n",
    "          df.to_csv('stack_overflow_posts.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n",
    "          print('Данные сохранены в stack_overflow_posts.csv')\n",
    "      except Exception as e:\n",
    "          print(f\"Ошибка при записи в CSV: {e}\")\n",
    "    else:\n",
    "        print(\"Нет данных для сохранения.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_posts = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        page = 1\n",
    "        has_more = True\n",
    "        keyword_posts = []\n",
    "        keyword_count = 0\n",
    "        \n",
    "\n",
    "        while has_more :\n",
    "            posts, has_more = get_posts(page=page, keyword=keyword)\n",
    "            keyword_posts.extend(posts)\n",
    "            page += 1\n",
    "            time.sleep(1)\n",
    "\n",
    "        all_posts.extend(keyword_posts)\n",
    "        \n",
    "\n",
    "    process_and_save(all_posts) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
